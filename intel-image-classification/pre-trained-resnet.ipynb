{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Deep learning\nimport torch \nimport torchvision\nimport torch.nn as nn\nfrom torchvision import models\nimport torchvision.transforms as transforms\n\n# Read Dataset\nimport cv2\nimport os\nfrom tqdm import tqdm\n\n# Show Image\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\n# Miscelanous\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-29T13:29:56.080893Z","iopub.execute_input":"2023-09-29T13:29:56.081296Z","iopub.status.idle":"2023-09-29T13:29:56.105669Z","shell.execute_reply.started":"2023-09-29T13:29:56.081265Z","shell.execute_reply":"2023-09-29T13:29:56.104654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset Path\nTRAIN_PATH = \"/kaggle/input/intel-image-classification/seg_train/seg_train\"\nTEST_PATH = \"/kaggle/input/intel-image-classification/seg_test/seg_test\"\nPRED_PATH = \"/kaggle/input/intel-image-classification/seg_pred/seg_pred\"","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:21:10.707319Z","iopub.execute_input":"2023-09-29T13:21:10.707784Z","iopub.status.idle":"2023-09-29T13:21:10.713633Z","shell.execute_reply.started":"2023-09-29T13:21:10.707745Z","shell.execute_reply":"2023-09-29T13:21:10.712526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:21:10.714843Z","iopub.execute_input":"2023-09-29T13:21:10.715737Z","iopub.status.idle":"2023-09-29T13:21:10.790848Z","shell.execute_reply.started":"2023-09-29T13:21:10.715699Z","shell.execute_reply":"2023-09-29T13:21:10.789641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datasaet Preparation","metadata":{}},{"cell_type":"code","source":"label_mapping = {\n    'buildings': 0,\n    'forest':1,\n    'glacier': 2,\n    'mountain': 3,\n    'sea': 4,\n    'street': 5 \n}","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:21:10.794315Z","iopub.execute_input":"2023-09-29T13:21:10.794634Z","iopub.status.idle":"2023-09-29T13:21:10.801103Z","shell.execute_reply.started":"2023-09-29T13:21:10.794595Z","shell.execute_reply":"2023-09-29T13:21:10.800350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    X = []\n    y = []\n    for category in os.listdir(path):\n        category_dir = os.path.join(path, category)\n        for img_file in tqdm(os.listdir(category_dir)):\n            img_path = os.path.join(category_dir, img_file)\n            img = cv2.imread(img_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (150,150))\n            # convert img to torch tensor\n            transform = transforms.ToTensor()\n            img = transform(img)\n            X.append(img)\n            y.append(label_mapping[category])\n            \n    y = torch.tensor(y)\n    return (X,y)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:21:10.802796Z","iopub.execute_input":"2023-09-29T13:21:10.803798Z","iopub.status.idle":"2023-09-29T13:21:10.812509Z","shell.execute_reply.started":"2023-09-29T13:21:10.803763Z","shell.execute_reply":"2023-09-29T13:21:10.811539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = read_data(TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:21:10.814232Z","iopub.execute_input":"2023-09-29T13:21:10.814791Z","iopub.status.idle":"2023-09-29T13:22:30.326171Z","shell.execute_reply.started":"2023-09-29T13:21:10.814760Z","shell.execute_reply":"2023-09-29T13:22:30.325144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"code","source":"class IntelDataset(torch.utils.data.Dataset):\n    def __init__(self, X, y):\n        self.images = X\n        self.labels = y\n    def __len__(self):\n        return len(self.images)\n    def __getitem__(self, idx):\n        return self.images[idx],self.labels[idx]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:22:30.327408Z","iopub.execute_input":"2023-09-29T13:22:30.328292Z","iopub.status.idle":"2023-09-29T13:22:30.334058Z","shell.execute_reply.started":"2023-09-29T13:22:30.328257Z","shell.execute_reply":"2023-09-29T13:22:30.333046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = IntelDataset(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:22:30.335402Z","iopub.execute_input":"2023-09-29T13:22:30.336258Z","iopub.status.idle":"2023-09-29T13:22:30.345498Z","shell.execute_reply.started":"2023-09-29T13:22:30.336223Z","shell.execute_reply":"2023-09-29T13:22:30.344318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loader","metadata":{}},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(\n    dataset=train_dataset,\n    batch_size=64,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:22:30.347057Z","iopub.execute_input":"2023-09-29T13:22:30.348157Z","iopub.status.idle":"2023-09-29T13:22:30.356595Z","shell.execute_reply.started":"2023-09-29T13:22:30.348123Z","shell.execute_reply":"2023-09-29T13:22:30.354572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show Image","metadata":{}},{"cell_type":"code","source":"def imshow(axis, inp):\n    \"\"\"Denormalize and show\"\"\"\n    axis.imshow(inp)\n\n    \ndef get_label(label_int):\n    label_mapping = {\n        0: 'buildings',\n        1: 'forest',\n        2: 'glacier',\n        3: 'mountain',\n        4: 'sea',\n        5: 'street'\n    }\n    return label_mapping[label_int]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:38:02.661941Z","iopub.execute_input":"2023-09-29T13:38:02.662326Z","iopub.status.idle":"2023-09-29T13:38:02.667677Z","shell.execute_reply.started":"2023-09-29T13:38:02.662291Z","shell.execute_reply":"2023-09-29T13:38:02.666472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = next(iter(train_loader))\nprint(img.size(), label.size())\n\nfig = plt.figure(1, figsize=(16, 4))\ngrid = ImageGrid(fig, 111, nrows_ncols=(1, 4), axes_pad=0.05)\n\nfor i in range(img[:4].size(0)):\n    ax = grid[i]\n    ax.imshow(img[i].permute(1, 2, 0))\n    ax.set_title(get_label(label[i].item()))\n    ax.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:38:48.672656Z","iopub.execute_input":"2023-09-29T13:38:48.673031Z","iopub.status.idle":"2023-09-29T13:38:49.301886Z","shell.execute_reply.started":"2023-09-29T13:38:48.672995Z","shell.execute_reply":"2023-09-29T13:38:49.301066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n\n# Freeze all layers except the classifier\nfor name, param in model.named_parameters():\n    if \"fc\" not in name: \n        param.requires_grad = False\n\n# add last layer with out_features=num_classes=6\nmodel.fc = nn.Linear(in_features=model.fc.in_features, out_features=6)\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:22:30.361021Z","iopub.execute_input":"2023-09-29T13:22:30.361925Z","iopub.status.idle":"2023-09-29T13:22:34.386170Z","shell.execute_reply.started":"2023-09-29T13:22:30.361891Z","shell.execute_reply":"2023-09-29T13:22:34.385225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:22:34.387524Z","iopub.execute_input":"2023-09-29T13:22:34.388034Z","iopub.status.idle":"2023-09-29T13:22:34.392400Z","shell.execute_reply.started":"2023-09-29T13:22:34.387995Z","shell.execute_reply":"2023-09-29T13:22:34.391242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:22:34.393672Z","iopub.execute_input":"2023-09-29T13:22:34.394233Z","iopub.status.idle":"2023-09-29T13:22:34.411581Z","shell.execute_reply.started":"2023-09-29T13:22:34.394199Z","shell.execute_reply":"2023-09-29T13:22:34.410608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(10):\n    model.train()\n    for i,(images,labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # backpropagation and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1)%110==0:\n            print (f'Epoch [{epoch+1}/{10}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:22:34.414008Z","iopub.execute_input":"2023-09-29T13:22:34.415371Z","iopub.status.idle":"2023-09-29T13:26:20.451770Z","shell.execute_reply.started":"2023-09-29T13:22:34.415337Z","shell.execute_reply":"2023-09-29T13:26:20.450812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"X_test, y_test = read_data(TEST_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:26:20.452961Z","iopub.execute_input":"2023-09-29T13:26:20.453310Z","iopub.status.idle":"2023-09-29T13:26:35.365463Z","shell.execute_reply.started":"2023-09-29T13:26:20.453278Z","shell.execute_reply":"2023-09-29T13:26:35.364477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = IntelDataset(X_test, y_test)\ntest_loader = torch.utils.data.DataLoader(\n    dataset=test_dataset,\n    batch_size=64,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:26:35.366916Z","iopub.execute_input":"2023-09-29T13:26:35.367266Z","iopub.status.idle":"2023-09-29T13:26:35.371889Z","shell.execute_reply.started":"2023-09-29T13:26:35.367229Z","shell.execute_reply":"2023-09-29T13:26:35.370767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images,labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        # predict\n        preds = model(images)\n        # get the label\n        _, predicted = torch.max(preds.data, 1)\n        # num of images\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    print(f'Test Accuracy of the model on the test images: {100 * correct / total}%')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T13:26:35.373073Z","iopub.execute_input":"2023-09-29T13:26:35.374394Z","iopub.status.idle":"2023-09-29T13:26:39.860018Z","shell.execute_reply.started":"2023-09-29T13:26:35.374336Z","shell.execute_reply":"2023-09-29T13:26:39.859077Z"},"trusted":true},"execution_count":null,"outputs":[]}]}